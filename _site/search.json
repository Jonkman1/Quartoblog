[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BlogProb",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nSankey diagrams and how to create\n\n\n\n\n\n\n\nexploration\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2022\n\n\nTim Verlaan\n\n\n\n\n\n\n  \n\n\n\n\nWrangling dates-time data\n\n\n\n\n\n\n\nexploration\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2022\n\n\nAlex Trinidad\n\n\n\n\n\n\n  \n\n\n\n\nResearch of Board Games\n\n\n\n\n\n\n\nexploration\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2022\n\n\nAsier Moreva\n\n\n\n\n\n\n  \n\n\n\n\nExploration and visualization of Starbuck coffee data\n\n\n\n\n\n\n\nexploration\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2022\n\n\nSam Langton\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThe NSC-R Tidy Tuesday workshop sessions are inspired by the Tidy Tuesday initiative, which was aimed at providing a safe and supportive forum for individuals to practice their data processing and visualization skills in R while working with real-world data.Here ten workshops are presented in ten posts\nIn the first post Sam Langton presents the exploration and visualization of Starbuck coffee-use data.\nThe second post is about board games and here Asier Moneva explores research questions like ‘What are the top 3 best-selling board games by game type?’ and ‘How do board game sales relate to online user ratings’. He shows how this can be explored and visualized.\nAlex Trinidad shows us in post nr. 3 how R and RStudio can be used to wrangle dates-time data.\nPost nr. 4 introduces us to Sankey diagrams, and how they can be created in R. Tim Verlaan is our mentor in this workshop.\nWim Bernaso introduces us in Post 5 to open footbal data which can be explored at various levels (player, team, match, competition) and from various perspectives.\nPost 6 (Sam Langton) demonstrates long to wide (and wide to long) transformations using functions available in the tidyrpackage. In this chapter data from the London Fire Brigade are used.\nPost 7 explores how revenue and expenditure are distributed in sports. In this chapter Alex Trinidad let us look at the differences in sport revenues and expenditures between men and women.\nIn post nr. 8 Wim Bernasco tries to make sense of long-term temporal trends in crimes, and to make useful statements about how things changed when the COVID pandemic arrived around February 2020. In this chapter eight steps in the analysis are worked out.\nAlso in post nr. 9 Wim Bernasco is the workshopleader. In this workshop, the focus is on exploring, analyzing, and visualizing student mobilisation streams between countries.\nPost nr. 10 is the last workshop presented here and this one is given by Franziska Yasrebi-de Kom, and is a descriptive analysis on a salary survey in different countries and some background variables of the participants."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html",
    "href": "posts/01_TT/01_TT_202201.html",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "",
    "text": "On 11 January 2022 and 25 January 2022 Sam Langton gave NSCR Tidy Tuesday presentations on the exploration and visualization of Starbuck coffee use data.In this document both presentations are combined [@langton_nsc-r_2022].\n\n\nHere you can find it on the NSCR- website. Here is the First presentation. Here is the Second presentation"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#load-libraries.",
    "href": "posts/01_TT/01_TT_202201.html#load-libraries.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Load libraries.",
    "text": "Load libraries.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#load-data",
    "href": "posts/01_TT/01_TT_202201.html#load-data",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Load data",
    "text": "Load data\nThe data are loaded directly from the TidyTuesday github page.\n\nstar_df <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-12-21/starbucks.csv')"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#initial-explore.",
    "href": "posts/01_TT/01_TT_202201.html#initial-explore.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Initial explore.",
    "text": "Initial explore.\nHere are some explorative commands you can use: - star-df opens the dataset and shows you the variables.\n- names(star_df)gives you the names of the 15 variables.\n- glimpse(star_df)shows you the number of rows (often particpants) and columns (often variables) and also informs you about the kind of variables.\n- dim(star_df) informs you about number of rows and columns.\n- sum(is.na(star_df)) show you the number of missing variables.\n\nstar_df\n\n# A tibble: 1,147 x 15\n   product_n~1 size   milk  whip serv_~2 calor~3 total~4 satur~5 trans~6 chole~7\n   <chr>       <chr> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>\n 1 brewed cof~ short     0     0     236       3     0.1       0 0             0\n 2 brewed cof~ tall      0     0     354       4     0.1       0 0             0\n 3 brewed cof~ gran~     0     0     473       5     0.1       0 0             0\n 4 brewed cof~ venti     0     0     591       5     0.1       0 0             0\n 5 brewed cof~ short     0     0     236       3     0.1       0 0             0\n 6 brewed cof~ tall      0     0     354       4     0.1       0 0             0\n 7 brewed cof~ gran~     0     0     473       5     0.1       0 0             0\n 8 brewed cof~ venti     0     0     591       5     0.1       0 0             0\n 9 brewed cof~ short     0     0     236       3     0.1       0 0             0\n10 brewed cof~ tall      0     0     354       4     0.1       0 0             0\n# ... with 1,137 more rows, 5 more variables: sodium_mg <dbl>,\n#   total_carbs_g <dbl>, fiber_g <chr>, sugar_g <dbl>, caffeine_mg <dbl>, and\n#   abbreviated variable names 1: product_name, 2: serv_size_m_l, 3: calories,\n#   4: total_fat_g, 5: saturated_fat_g, 6: trans_fat_g, 7: cholesterol_mg\n\nnames(star_df)\n\n [1] \"product_name\"    \"size\"            \"milk\"            \"whip\"           \n [5] \"serv_size_m_l\"   \"calories\"        \"total_fat_g\"     \"saturated_fat_g\"\n [9] \"trans_fat_g\"     \"cholesterol_mg\"  \"sodium_mg\"       \"total_carbs_g\"  \n[13] \"fiber_g\"         \"sugar_g\"         \"caffeine_mg\"    \n\nglimpse(star_df)\n\nRows: 1,147\nColumns: 15\n$ product_name    <chr> \"brewed coffee - dark roast\", \"brewed coffee - dark ro~\n$ size            <chr> \"short\", \"tall\", \"grande\", \"venti\", \"short\", \"tall\", \"~\n$ milk            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, ~\n$ whip            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ serv_size_m_l   <dbl> 236, 354, 473, 591, 236, 354, 473, 591, 236, 354, 473,~\n$ calories        <dbl> 3, 4, 5, 5, 3, 4, 5, 5, 3, 4, 5, 5, 3, 4, 5, 5, 35, 50~\n$ total_fat_g     <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,~\n$ saturated_fat_g <dbl> 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,~\n$ trans_fat_g     <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\",~\n$ cholesterol_mg  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10,~\n$ sodium_mg       <dbl> 5, 10, 10, 10, 5, 10, 10, 10, 5, 5, 5, 5, 5, 5, 5, 5, ~\n$ total_carbs_g   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, ~\n$ fiber_g         <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\",~\n$ sugar_g         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, ~\n$ caffeine_mg     <dbl> 130, 193, 260, 340, 15, 20, 25, 30, 155, 235, 310, 410~\n\ndim(star_df)\n\n[1] 1147   15\n\nsum(is.na(star_df))\n\n[1] 0"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#subset-brewed-coffee.",
    "href": "posts/01_TT/01_TT_202201.html#subset-brewed-coffee.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Subset brewed coffee.",
    "text": "Subset brewed coffee.\nWhen you want to look at a specific subset with the product_name brewed coffee for example you can define this as:.\n\nbrew_df <- star_df |>\n  filter(str_detect(product_name, \"brewed coffee\"))"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#quick-clean-for-the-plot.",
    "href": "posts/01_TT/01_TT_202201.html#quick-clean-for-the-plot.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Quick clean for the plot.",
    "text": "Quick clean for the plot.\n\nMake another subsample and call it big_ones_df. -Use only the variables product_name, size, milk, whip and calories-trans_fat_g).\n\nUse only when sizeis grande.\nchange whip into a character variable.\nRecode categories of milkfrom 0, 1, 2, 3, 4 5 into no milk, non-fat, 2% fat, soy, coconut, whole.\n\n\nbig_ones_df <- star_df |>\n  select(product_name, size, milk, whip, calories:trans_fat_g) |> \n  filter(size == \"grande\") |>\n  mutate(whip_char = as.character(whip),\n         milk_labs = recode(milk,\n                            `0` = \"no milk\",\n                            `1` = \"non-fat\",\n                            `2` = \"2% fat\",\n                            `3` = \"soy\",\n                            `4` = \"coconut\",\n                            `5` = \"whole\")) # These categories are on the tt git page."
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#what-is-the-relationship-between-calories-and-fat",
    "href": "posts/01_TT/01_TT_202201.html#what-is-the-relationship-between-calories-and-fat",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "What is the relationship between calories and fat?",
    "text": "What is the relationship between calories and fat?\nCan you plot between calories(y) and total_fat_g (x)? Show the diffence on whip_char'and show it for the sixmilk-labs` you recoded.\n\nmy_plot_gg <- ggplot(data = big_ones_df) +\n  geom_point(mapping = aes(x = total_fat_g, y = calories, fill = whip_char),\n             size = 2, alpha = 0.8, pch = 21, colour = \"black\") +\n  facet_wrap(~milk_labs) +\n  labs(title = \"Starbucks: fat, calories and milk types\",\n       caption = \"Data notes: grande drink size | Data source: tidytuesday | NSC-R workshop 11 Jan 2022\",\n       fill = NULL, x = \"total fat (grams)\") +\n  scale_fill_manual(values = c(\"#036635\", \"#b5651d\"),\n                      labels = c(\"Without whipped cream\", \"With whipped cream\")) +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        axis.text = element_text(size = 6),\n        axis.title = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5),\n        plot.caption = element_text(size = 4))\nmy_plot_gg\n\n\n\n\nStarbucks coffeetypes"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#save.",
    "href": "posts/01_TT/01_TT_202201.html#save.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Save.",
    "text": "Save.\nSave the plot on your computer as a png-file. Here is place in a projectmap and a submap images which I made on my computer. Change the path if necessary for your computer.\n\nggsave(my_plot_gg, file = \"images/starbucks_plot.png\",\n       height = 12, width = 12, unit = \"cm\")"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#counting-frequencies",
    "href": "posts/01_TT/01_TT_202201.html#counting-frequencies",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Counting frequencies",
    "text": "Counting frequencies\nFor counting frequencies you always can use different methods. We show some of them.\nThis is the R base-way for counting the variable whipfor example.\n\ntable(star_df$whip)\n\n\n  0   1 \n864 283 \n\n\nThis is the grouping-way.\n\nstar_df |>\n  group_by(whip) |> \n  tally() \n\n# A tibble: 2 x 2\n   whip     n\n  <dbl> <int>\n1     0   864\n2     1   283\n\n\nThis is a better way (thanks Wim!).\n\nfreq_df <- count(star_df, whip)\nfreq_df\n\n# A tibble: 2 x 2\n   whip     n\n  <dbl> <int>\n1     0   864\n2     1   283"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#basic-cleaning",
    "href": "posts/01_TT/01_TT_202201.html#basic-cleaning",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Basic cleaning",
    "text": "Basic cleaning\nHere we do some basic cleaning. We select six variables and look only at variables of which the size is grande. We call this dataset star_clean.\n\nstar_clean_df <- star_df |>\n  select(product_name, size, milk, whip, calories, sugar_g) |>\n  filter(size == \"grande\")"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#basic-plot",
    "href": "posts/01_TT/01_TT_202201.html#basic-plot",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Basic plot",
    "text": "Basic plot\nLet us plot it on different ways.The first three are similar.\n\nggplot(data = star_clean_df, mapping = aes(x = sugar_g, y = calories)) +\n  geom_point()\n\nggplot(data = star_clean_df) +\n  geom_point(mapping = aes(x = sugar_g, y = calories))\n\nggplot() +\n  geom_point(data = star_clean_df, mapping = aes(x = sugar_g, y = calories))\n\n\n\n\n\n\nFirst way\n\n\n\n\n\n\n\nSecond way\n\n\n\n\n\n\n\nThird way\n\n\n\n\n\n\nRelation between sugar and calories\n\n\n\n\nThen we plot the coffee of which the whipis 1.\n\nstar_clean_df |>\n  filter(whip == 1) |>\n  ggplot() +\n  geom_point(mapping = aes(x = sugar_g, y = calories))\n\n\n\n\nRelation between sugar and calories with coffee whip-1"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#change-milk-class.",
    "href": "posts/01_TT/01_TT_202201.html#change-milk-class.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Change milk class.",
    "text": "Change milk class.\nFor the next plot we first change the class of the variable milk into a character variable and save it as a different dataset.\n\nstar_clean_df <- star_clean_df |> \n  mutate(milk_char = as.character(milk))"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#extend.",
    "href": "posts/01_TT/01_TT_202201.html#extend.",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Extend.",
    "text": "Extend.\nWe plot this new dataset on three different ways.\n\nggplot(data = star_clean_df) +\n  geom_point (mapping = aes(x = sugar_g, y = calories)) +\n  geom_smooth(mapping = aes(x = sugar_g, y = calories), method = \"lm\") +\n  facet_wrap(~milk_char)\n\nggplot(data = star_clean_df, mapping = aes(x = sugar_g, y = calories)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(vars(milk_char, whip))\n\n\nggplot(data = star_clean_df) +\n  geom_point(mapping = aes(x = sugar_g, y = calories, shape = milk_char, colour = milk_char))\n\n\n\n\n\n\nFirst way\n\n\n\n\n\n\n\nSecond way\n\n\n\n\n\n\n\nThird way\n\n\n\n\n\n\nRelation between sugar and calories with coffee whip-1"
  },
  {
    "objectID": "posts/01_TT/01_TT_202201.html#reference",
    "href": "posts/01_TT/01_TT_202201.html#reference",
    "title": "Exploration and visualization of Starbuck coffee data",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html",
    "href": "posts/02_TT/02_TT_202202.html",
    "title": "Research of Board Games",
    "section": "",
    "text": "The dataset for this Tidy Tuesday is about board games! Asier Moneva explores the following research questions: “What are the top 3 best-selling board games by game type?” and “How do board game sales relate to online user ratings?”[@moneva_nsc-r_2022]"
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html#load-packages",
    "href": "posts/02_TT/02_TT_202202.html#load-packages",
    "title": "Research of Board Games",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nToday’s data are relational, which means there are multiple datasets (rating, details) that can be linked through some identifier or id variable or ‘key’."
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html#import-data",
    "href": "posts/02_TT/02_TT_202202.html#import-data",
    "title": "Research of Board Games",
    "section": "Import data",
    "text": "Import data\n\nratings <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/ratings.csv\")\n\n\ndetails <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/details.csv\")"
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html#explore-data",
    "href": "posts/02_TT/02_TT_202202.html#explore-data",
    "title": "Research of Board Games",
    "section": "Explore data",
    "text": "Explore data\nSo let’s have a quick look at the data.\n\nglimpse(ratings)\n\nRows: 21,831\nColumns: 10\n$ num           <dbl> 105, 189, 428, 72, 103, 191, 100, 3, 15, 35, 30, 182, 13~\n$ id            <dbl> 30549, 822, 13, 68448, 36218, 9209, 178900, 167791, 1733~\n$ name          <chr> \"Pandemic\", \"Carcassonne\", \"Catan\", \"7 Wonders\", \"Domini~\n$ year          <dbl> 2008, 2000, 1995, 2010, 2008, 2004, 2015, 2016, 2015, 20~\n$ rank          <dbl> 106, 190, 429, 73, 104, 192, 101, 4, 16, 36, 31, 183, 14~\n$ average       <dbl> 7.59, 7.42, 7.14, 7.74, 7.61, 7.41, 7.60, 8.42, 8.11, 7.~\n$ bayes_average <dbl> 7.487, 7.309, 6.970, 7.634, 7.499, 7.305, 7.508, 8.274, ~\n$ users_rated   <dbl> 108975, 108738, 108024, 89982, 81561, 76171, 74419, 7421~\n$ url           <chr> \"/boardgame/30549/pandemic\", \"/boardgame/822/carcassonne~\n$ thumbnail     <chr> \"https://cf.geekdo-images.com/S3ybV1LAp-8SnHIXLLjVqA__mi~\n\nglimpse(details)\n\nRows: 21,631\nColumns: 23\n$ num                     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ~\n$ id                      <dbl> 30549, 822, 13, 68448, 36218, 9209, 178900, 16~\n$ primary                 <chr> \"Pandemic\", \"Carcassonne\", \"Catan\", \"7 Wonders~\n$ description             <chr> \"In Pandemic, several virulent diseases have b~\n$ yearpublished           <dbl> 2008, 2000, 1995, 2010, 2008, 2004, 2015, 2016~\n$ minplayers              <dbl> 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2, 2, 2~\n$ maxplayers              <dbl> 4, 5, 4, 7, 4, 5, 8, 5, 2, 5, 5, 4, 5, 5, 5, 4~\n$ playingtime             <dbl> 45, 45, 120, 30, 30, 60, 15, 120, 30, 150, 150~\n$ minplaytime             <dbl> 45, 30, 60, 30, 30, 30, 15, 120, 30, 30, 90, 3~\n$ maxplaytime             <dbl> 45, 45, 120, 30, 30, 60, 15, 120, 30, 150, 150~\n$ minage                  <dbl> 8, 7, 10, 10, 13, 8, 14, 12, 10, 12, 12, 10, 1~\n$ boardgamecategory       <chr> \"['Medical']\", \"['City Building', 'Medieval', ~\n$ boardgamemechanic       <chr> \"['Action Points', 'Cooperative Game', 'Hand M~\n$ boardgamefamily         <chr> \"['Components: Map (Global Scale)', 'Component~\n$ boardgameexpansion      <chr> \"['Pandemic: Gen Con 2016 Promos – Z-Force Tea~\n$ boardgameimplementation <chr> \"['Pandemic Legacy: Season 0', 'Pandemic Legac~\n$ boardgamedesigner       <chr> \"['Matt Leacock']\", \"['Klaus-Jürgen Wrede']\", ~\n$ boardgameartist         <chr> \"['Josh Cappel', 'Christian Hanisch', 'Régis M~\n$ boardgamepublisher      <chr> \"['Z-Man Games', 'Albi', 'Asmodee', 'Asmodee I~\n$ owned                   <dbl> 168364, 161299, 167733, 120466, 106956, 105748~\n$ trading                 <dbl> 2508, 1716, 2018, 1567, 2009, 930, 1110, 538, ~\n$ wanting                 <dbl> 625, 582, 485, 1010, 655, 692, 340, 2011, 924,~\n$ wishing                 <dbl> 9344, 7383, 5890, 12105, 8621, 6620, 5764, 192~\n\n\nYou see that the number of observations do not match!\nExplore whether both datasets have identical id\n\nidentical(details$id, ratings$id)\n\n[1] FALSE\n\n\nCount how many id are missing.\n\ntable(ratings$id %in% details$id)\n\n\nFALSE  TRUE \n  200 21631 \n\n\nFind which id are present in both datasets. Results not show here because of too long output.\n\nintersect(details$id, ratings$id)\n\nFind which id are absent in the dataset with the least observations\n\nsetdiff(ratings$id, details$id)\n\n  [1] 298130 286790   2415  12369  25999 304051 262554  67499  16268 236881\n [11] 102750  15391  10889   4875 165190 225303  18536 192323 143663  18704\n [21]  33125 297139   7578  32922 143459 237088 311004 195158  12624 201917\n [31]  34403  18061   5043  15049  23733 225828   6913 176633 198541  64608\n [41]   3610  29268 244268 177566  38836 275284  10544 284617 191292  96626\n [51]   8741   7752 136856  12900  30335 189615 183344  36238  39663 314125\n [61] 325678 246310 109827  19475  31412  69233   5649  98978   3814 140973\n [71] 265039  39278 188968 144378 303676  20533  13094   9860 310880 304666\n [81] 279649  40804   8249 245060 246895  10246  14698 172088   6124  20647\n [91] 264654 299690 147457  23616 258761 311990 132616 154841   8356 216360\n[101]  12169 226237 118561  49050 282410   2493   9398   9578   9512  24079\n[111]   3398 147616   7368 170390  36993  23999 316090  11674   9454  34129\n[121] 252901  10105 287304 164428  41611 232874   1550 252373   3909 145206\n[131]  36366 308870  24857 210350   6839 125585   9113 145400 239523  16830\n[141]  19304  40886  21437 328866 244528 252374  17996  22354 283849  14128\n[151] 305270 237834 137366  38524   3338   1221 319593   3830 102150  10154\n[161] 208800 214486  32324  86443 162888 221208 241611  17433   9736  18687\n[171] 104770   8426 247135 233284  11421  13918  31585   2103 210292 276641\n[181] 289055  15427  24994  47475  66276 205156   3047   8700 306072  14377\n[191]   1191 251026  19044 282389 296644 284839 144874 179124 150429  35499\n\n\nMerge data\n\ndf <- inner_join(ratings, details, by = \"id\")\n\nExplore data\n\nglimpse(df)\n\nRows: 21,631\nColumns: 32\n$ num.x                   <dbl> 105, 189, 428, 72, 103, 191, 100, 3, 15, 35, 3~\n$ id                      <dbl> 30549, 822, 13, 68448, 36218, 9209, 178900, 16~\n$ name                    <chr> \"Pandemic\", \"Carcassonne\", \"Catan\", \"7 Wonders~\n$ year                    <dbl> 2008, 2000, 1995, 2010, 2008, 2004, 2015, 2016~\n$ rank                    <dbl> 106, 190, 429, 73, 104, 192, 101, 4, 16, 36, 3~\n$ average                 <dbl> 7.59, 7.42, 7.14, 7.74, 7.61, 7.41, 7.60, 8.42~\n$ bayes_average           <dbl> 7.487, 7.309, 6.970, 7.634, 7.499, 7.305, 7.50~\n$ users_rated             <dbl> 108975, 108738, 108024, 89982, 81561, 76171, 7~\n$ url                     <chr> \"/boardgame/30549/pandemic\", \"/boardgame/822/c~\n$ thumbnail               <chr> \"https://cf.geekdo-images.com/S3ybV1LAp-8SnHIX~\n$ num.y                   <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ~\n$ primary                 <chr> \"Pandemic\", \"Carcassonne\", \"Catan\", \"7 Wonders~\n$ description             <chr> \"In Pandemic, several virulent diseases have b~\n$ yearpublished           <dbl> 2008, 2000, 1995, 2010, 2008, 2004, 2015, 2016~\n$ minplayers              <dbl> 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2, 2, 2~\n$ maxplayers              <dbl> 4, 5, 4, 7, 4, 5, 8, 5, 2, 5, 5, 4, 5, 5, 5, 4~\n$ playingtime             <dbl> 45, 45, 120, 30, 30, 60, 15, 120, 30, 150, 150~\n$ minplaytime             <dbl> 45, 30, 60, 30, 30, 30, 15, 120, 30, 30, 90, 3~\n$ maxplaytime             <dbl> 45, 45, 120, 30, 30, 60, 15, 120, 30, 150, 150~\n$ minage                  <dbl> 8, 7, 10, 10, 13, 8, 14, 12, 10, 12, 12, 10, 1~\n$ boardgamecategory       <chr> \"['Medical']\", \"['City Building', 'Medieval', ~\n$ boardgamemechanic       <chr> \"['Action Points', 'Cooperative Game', 'Hand M~\n$ boardgamefamily         <chr> \"['Components: Map (Global Scale)', 'Component~\n$ boardgameexpansion      <chr> \"['Pandemic: Gen Con 2016 Promos – Z-Force Tea~\n$ boardgameimplementation <chr> \"['Pandemic Legacy: Season 0', 'Pandemic Legac~\n$ boardgamedesigner       <chr> \"['Matt Leacock']\", \"['Klaus-Jürgen Wrede']\", ~\n$ boardgameartist         <chr> \"['Josh Cappel', 'Christian Hanisch', 'Régis M~\n$ boardgamepublisher      <chr> \"['Z-Man Games', 'Albi', 'Asmodee', 'Asmodee I~\n$ owned                   <dbl> 168364, 161299, 167733, 120466, 106956, 105748~\n$ trading                 <dbl> 2508, 1716, 2018, 1567, 2009, 930, 1110, 538, ~\n$ wanting                 <dbl> 625, 582, 485, 1010, 655, 692, 340, 2011, 924,~\n$ wishing                 <dbl> 9344, 7383, 5890, 12105, 8621, 6620, 5764, 192~\n\n\nLooks like there are some duplicated variables!\nNot really\n\nidentical(df$year, df$yearpublished)\n\n[1] FALSE\n\n\nWhat is the difference?\n\nwhich(df$year != df$yearpublished)\n\n [1]   209   297   881  1030  2239  3623  4089  4723 15507 16494 21623\n\n\nAh, I see!\n\ndf$year[21623]\n\n[1] 3000\n\ndf$yearpublished[21623]\n\n[1] -3000\n\n\nNope. Very different. Can these be row numbers (e.g. spreadsheet)?\n\nidentical(df$num.x, df$num.y)\n\n[1] FALSE\n\n\nAlmost, but nope.\n\nidentical(df$name, df$primary)\n\n[1] FALSE\n\nwhich(df$name != df$primary)\n\n[1]  7222 10903 12599 13233 19925\n\n\nLooks like there is some sort of syntax issue in primary\n\ndf$name[19925]\n\n[1] \"Admiral Ackbar \\\"It's a TRAP!\\\" GAME\"\n\ndf$primary[19925]\n\n[1] \"Admiral Ackbar \\\"It\\\\'s a TRAP!\\\" GAME\"\n\n\nBingo!\n\nidentical(df$playingtime, df$maxplaytime)\n\n[1] TRUE\n\n\nLet’s drop the duplicated variable\n\ndf <- df %>% \n  select(\n    - playingtime,\n    - primary\n  )\n\nLooks like we are good now! Imagine the following:\n\nWe want to buy a board game for a friend, but we don’t know which one to get.\nWe know our friend likes to play alone with his girlfriend sometimes, but some Other times he likes to invite friends over to play.\nWhat are the top 3 best-selling board games by game type?\nHow do board game sales relate to online user ratings?\nWhat are the top 3 best-selling board games by game type?\n\n\ndf <- df |> \n  # Create new variable to define type of game based on number of players\n  mutate(minplayers_fct = case_when(\n    minplayers < 2 ~ \"single player\",\n    minplayers == 2 ~ \"two players\",\n    minplayers > 2 ~ \"multiplayer\"\n  ))\n\n\ndf |> \n  # Select only relevant variables\n  select(\n    name,\n    minplayers_fct,\n    owned\n  ) |> \n  group_by(minplayers_fct) |> \n  slice_max(owned, n = 3) |> \n  knitr::kable()\n\n\n\n\nname\nminplayers_fct\nowned\n\n\n\n\nCatan\nmultiplayer\n167733\n\n\nMunchkin\nmultiplayer\n78849\n\n\nDixit\nmultiplayer\n76535\n\n\nTerraforming Mars\nsingle player\n101872\n\n\nScythe\nsingle player\n86371\n\n\nWingspan\nsingle player\n83920\n\n\nPandemic\ntwo players\n168364\n\n\nCarcassonne\ntwo players\n161299\n\n\n7 Wonders\ntwo players\n120466\n\n\n\n\n\nWe have identified the best-sellers for each category, but best-sellers might be a product of marketing rather than an indicator of good quality. It might be the case that players buy the product because of good marketing but then find the game boring, too complicated, etc.\nHow do board game sales relate to online user ratings?"
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html#plot-data",
    "href": "posts/02_TT/02_TT_202202.html#plot-data",
    "title": "Research of Board Games",
    "section": "Plot data",
    "text": "Plot data\n\ndf %>% \n  ggplot(mapping = aes(\n    x = average,\n    y = owned,\n    # Examine if there are clear patterns by number of players\n    color = minplayers_fct\n  )) +\n  geom_point(alpha = .5) +\n  # There seems to be three outliers that are best-sellers and also have high \n  # ratings\n  ggrepel::geom_text_repel(\n    data = df |> filter(owned > 150000),\n    mapping = aes(label = name),\n    color = \"black\"\n    ) +\n  scale_x_continuous(limits = c(0, 10)) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"How do board game sales relate to online user ratings?\",\n    x = \"average user rating\",\n    y = \"number of\\ncopies owned\",\n    color = \"Category\"\n  ) +\n  theme_classic() +\n  theme(axis.title.y = element_text(\n    angle = 0,\n    vjust = .5\n  ))\n\n\n\n\nRelation board game sales and online user ratings"
  },
  {
    "objectID": "posts/02_TT/02_TT_202202.html#references",
    "href": "posts/02_TT/02_TT_202202.html#references",
    "title": "Research of Board Games",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "posts/03_TT/03_TT_202202.html",
    "href": "posts/03_TT/03_TT_202202.html",
    "title": "Wrangling dates-time data",
    "section": "",
    "text": "The dataset for this Tidy Tuesday is about animal rescues! Alex Trinidad explores the temporal trends of animal rescues using lubridate package (Grolemund & Wickham, 2011) [@trinidad_nsc-r_nodate]"
  },
  {
    "objectID": "posts/03_TT/03_TT_202202.html#load-packages-and-data",
    "href": "posts/03_TT/03_TT_202202.html#load-packages-and-data",
    "title": "Wrangling dates-time data",
    "section": "Load packages and data",
    "text": "Load packages and data\nInstall TT package (if necessary)\ninstall.packages(\"tidytuesdayR\")\ninstall.packages(\"tidyverse\")\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(tidytuesdayR)\n\nDownload data.\n\nmydatalist <- tidytuesdayR::tt_load(\"2021-06-29\")\n\n\n    Downloading file 1 of 1: `animal_rescues.csv`\n\n\nData as tbl\n\nmydata <- mydatalist$animal_rescues"
  },
  {
    "objectID": "posts/03_TT/03_TT_202202.html#explore-the-data",
    "href": "posts/03_TT/03_TT_202202.html#explore-the-data",
    "title": "Wrangling dates-time data",
    "section": "Explore the data",
    "text": "Explore the data\n\nglimpse(mydata)\n\nRows: 7,544\nColumns: 31\n$ incident_number               <dbl> 139091, 275091, 2075091, 2872091, 355309~\n$ date_time_of_call             <chr> \"01/01/2009 03:01\", \"01/01/2009 08:51\", ~\n$ cal_year                      <dbl> 2009, 2009, 2009, 2009, 2009, 2009, 2009~\n$ fin_year                      <chr> \"2008/09\", \"2008/09\", \"2008/09\", \"2008/0~\n$ type_of_incident              <chr> \"Special Service\", \"Special Service\", \"S~\n$ pump_count                    <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", ~\n$ pump_hours_total              <chr> \"2\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", ~\n$ hourly_notional_cost          <dbl> 255, 255, 255, 255, 255, 255, 255, 255, ~\n$ incident_notional_cost        <chr> \"510\", \"255\", \"255\", \"255\", \"255\", \"255\"~\n$ final_description             <chr> \"Redacted\", \"Redacted\", \"Redacted\", \"Red~\n$ animal_group_parent           <chr> \"Dog\", \"Fox\", \"Dog\", \"Horse\", \"Rabbit\", ~\n$ originof_call                 <chr> \"Person (land line)\", \"Person (land line~\n$ property_type                 <chr> \"House - single occupancy\", \"Railings\", ~\n$ property_category             <chr> \"Dwelling\", \"Outdoor Structure\", \"Outdoo~\n$ special_service_type_category <chr> \"Other animal assistance\", \"Other animal~\n$ special_service_type          <chr> \"Animal assistance involving livestock -~\n$ ward_code                     <chr> \"E05011467\", \"E05000169\", \"E05000558\", \"~\n$ ward                          <chr> \"Crystal Palace & Upper Norwood\", \"Woods~\n$ borough_code                  <chr> \"E09000008\", \"E09000008\", \"E09000029\", \"~\n$ borough                       <chr> \"Croydon\", \"Croydon\", \"Sutton\", \"Hilling~\n$ stn_ground_name               <chr> \"Norbury\", \"Woodside\", \"Wallington\", \"Ru~\n$ uprn                          <chr> \"NULL\", \"NULL\", \"NULL\", \"1.00021E+11\", \"~\n$ street                        <chr> \"Waddington Way\", \"Grasmere Road\", \"Mill~\n$ usrn                          <chr> \"20500146\", \"NULL\", \"NULL\", \"21401484\", ~\n$ postcode_district             <chr> \"SE19\", \"SE25\", \"SM5\", \"UB9\", \"RM3\", \"RM~\n$ easting_m                     <chr> \"NULL\", \"534785\", \"528041\", \"504689\", \"N~\n$ northing_m                    <chr> \"NULL\", \"167546\", \"164923\", \"190685\", \"N~\n$ easting_rounded               <dbl> 532350, 534750, 528050, 504650, 554650, ~\n$ northing_rounded              <dbl> 170050, 167550, 164950, 190650, 192350, ~\n$ latitude                      <chr> \"NULL\", \"51.39095371\", \"51.36894086\", \"5~\n$ longitude                     <chr> \"NULL\", \"-0.064166887\", \"-0.161985191\", ~\n\n\nDo we have missing data?\n\nsummary(mydata)\n\n incident_number     date_time_of_call     cal_year      fin_year        \n Min.   :     4149   Length:7544        Min.   :2009   Length:7544       \n 1st Qu.: 49306118   Class :character   1st Qu.:2012   Class :character  \n Median : 89438626   Mode  :character   Median :2015   Mode  :character  \n Mean   : 91854662                      Mean   :2015                     \n 3rd Qu.:131567118                      3rd Qu.:2018                     \n Max.   :233284091                      Max.   :2021                     \n NA's   :3478                                                            \n type_of_incident    pump_count        pump_hours_total   hourly_notional_cost\n Length:7544        Length:7544        Length:7544        Min.   :255.0       \n Class :character   Class :character   Class :character   1st Qu.:260.0       \n Mode  :character   Mode  :character   Mode  :character   Median :298.0       \n                                                          Mean   :301.3       \n                                                          3rd Qu.:333.0       \n                                                          Max.   :352.0       \n                                                                              \n incident_notional_cost final_description  animal_group_parent\n Length:7544            Length:7544        Length:7544        \n Class :character       Class :character   Class :character   \n Mode  :character       Mode  :character   Mode  :character   \n                                                              \n                                                              \n                                                              \n                                                              \n originof_call      property_type      property_category \n Length:7544        Length:7544        Length:7544       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n special_service_type_category special_service_type  ward_code        \n Length:7544                   Length:7544          Length:7544       \n Class :character              Class :character     Class :character  \n Mode  :character              Mode  :character     Mode  :character  \n                                                                      \n                                                                      \n                                                                      \n                                                                      \n     ward           borough_code         borough          stn_ground_name   \n Length:7544        Length:7544        Length:7544        Length:7544       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     uprn              street              usrn           postcode_district \n Length:7544        Length:7544        Length:7544        Length:7544       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  easting_m          northing_m        easting_rounded  northing_rounded\n Length:7544        Length:7544        Min.   :500050   Min.   :157050  \n Class :character   Class :character   1st Qu.:524750   1st Qu.:175150  \n Mode  :character   Mode  :character   Median :531650   Median :181250  \n                                       Mean   :531243   Mean   :180725  \n                                       3rd Qu.:537750   3rd Qu.:186750  \n                                       Max.   :571350   Max.   :200750  \n                                                                        \n   latitude          longitude        \n Length:7544        Length:7544       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n                                      \n\n\nCreate a unique ID\n\nmydata <- mydata |> \n  arrange(cal_year) |> \n  mutate(uid = paste0(seq(1:n()), LETTERS, letters))\n\nAre there any duplicated?\n\ntable(duplicated(mydata$uid))\n\n\nFALSE \n 7544 \n\n\nSelect variables of interest.\n\nmydataselection <- mydata |> \n  select(uid, date_time_of_call, type_of_incident, animal_group_parent, borough_code)\n\nShow me the frequencies of different types of animal.\n\nmyfreq <- mydataselection |> \n  group_by(animal_group_parent) |> \n  summarise(freq = n()) |> \n  arrange(-freq)\nmyfreq\n\n# A tibble: 28 x 2\n   animal_group_parent               freq\n   <chr>                            <int>\n 1 Cat                               3649\n 2 Bird                              1530\n 3 Dog                               1194\n 4 Fox                                349\n 5 Horse                              193\n 6 Unknown - Domestic Animal Or Pet   191\n 7 Deer                               130\n 8 Unknown - Wild Animal               89\n 9 Squirrel                            65\n10 Unknown - Heavy Livestock Animal    49\n# ... with 18 more rows\n\n\nRemove unkonwn type of animals from the dataset.\n\nmydataselection <- mydataselection |> \n  filter(!grepl(\"Unknown\", animal_group_parent))\n\n\nmyfreq <- mydataselection |> \n  group_by(animal_group_parent) |> \n  summarise(freq = n()) |> \n  arrange(-freq)\n\nMerging the cat counts.\n\nmydataselection$animal_group_parent <- recode(mydataselection$animal_group_parent,\n                                              \"cat\" = \"Cat\")\n\nAnother way to do this (Nick van Doormaal suggestion).\n\nmydataselection$animal_group_parent <- tolower(mydataselection$animal_group_parent)"
  },
  {
    "objectID": "posts/03_TT/03_TT_202202.html#working-with-date-time-data",
    "href": "posts/03_TT/03_TT_202202.html#working-with-date-time-data",
    "title": "Wrangling dates-time data",
    "section": "Working with Date-Time Data",
    "text": "Working with Date-Time Data\nNow we are ready to work with Data-Time Data. We want to separate the date in year, month, day, hour….\nBut, what variable type is the date in our data set?\n\nglimpse(mydataselection)\n\nRows: 7,211\nColumns: 5\n$ uid                 <chr> \"1Aa\", \"2Bb\", \"3Cc\", \"4Dd\", \"5Ee\", \"7Gg\", \"8Hh\", \"~\n$ date_time_of_call   <chr> \"01/01/2009 03:01\", \"01/01/2009 08:51\", \"04/01/200~\n$ type_of_incident    <chr> \"Special Service\", \"Special Service\", \"Special Ser~\n$ animal_group_parent <chr> \"dog\", \"fox\", \"dog\", \"horse\", \"rabbit\", \"dog\", \"do~\n$ borough_code        <chr> \"E09000008\", \"E09000008\", \"E09000029\", \"E09000017\"~\n\n\nIf not “date” format, transform ir\n\nmydatadate <- mydataselection |> \n  mutate(datetime = lubridate::as_datetime(date_time_of_call, \n                                   format = \"%d/%m/%Y %H:%M\"))\n# # Non-lubridate Alternative\n# mydatadate <- mydataselection |> \n#   mutate(datetime = strptime(date_time_of_call,\n#                          format =\"%d/%m/%Y %H:%M\", \n#                          tz = \"Europe/London\"))\n# OlsonNames() # function for for the tz\n\nCreate separate variables for day, month, year, hour, minute, and date.\n\nmydatadate <- mydataselection |> \n  mutate(datetime = as_datetime(date_time_of_call,\n                            format =\"%d/%m/%Y %H:%M\"),\n         day = day(datetime),\n         month = month(datetime),\n         year = year(datetime),\n         hour = hour(datetime),\n         minute = minute(datetime),\n         date = as_date(datetime))\n\nhead(mydatadate[, 6:12])\n\n# A tibble: 6 x 7\n  datetime              day month  year  hour minute date      \n  <dttm>              <int> <dbl> <dbl> <int>  <int> <date>    \n1 2009-01-01 03:01:00     1     1  2009     3      1 2009-01-01\n2 2009-01-01 08:51:00     1     1  2009     8     51 2009-01-01\n3 2009-01-04 10:07:00     4     1  2009    10      7 2009-01-04\n4 2009-01-05 12:27:00     5     1  2009    12     27 2009-01-05\n5 2009-01-06 15:23:00     6     1  2009    15     23 2009-01-06\n6 2009-01-07 06:29:00     7     1  2009     6     29 2009-01-07\n\n\nHow many cases do we have now per day?\n\ncaseperday <- mydatadate |> \n  group_by(date) |> \n  summarise(resc_counts = n())\n\nPlot trends of cases\n\nggplot(data = caseperday, \n       aes(\n         x = date,\n         y = resc_counts\n       )) +\n  geom_line()\n\n\n\n\nTrends of cases\n\n\n\n\nAnd how many cases do we have per year?\n\nmydatadate |> \n  group_by(year) %>% \n  summarise(resc_counts = n()) |> \n  ggplot() +\n  aes(\n    x = year,\n    y = resc_counts\n  ) + \n  geom_line()\n\n\n\n\nHow many cases per year\n\n\n\n\nIs there a rescue every day?\n\nperday <- mydatadate |> \n          group_by(date) |> \n          summarise(resc_counts = n())\n\nHow many days are (more or less) in those years?\n\nlength(unique(mydatadate$year)) * 365\n\n[1] 4745\n\n\nHow can I know the days that are missing? Create for this a data set with all the days\n\ncompdates <- data.frame(date = c(seq(ymd('2009-01-01'), \n                                     ymd('2021-12-31'), by = '1 day')))\n\nHow can I know the days that are missing? Create for this a data set with all the days\n\ncompdates <- data.frame(date = c(seq(ymd('2009-01-01'), \n                                     ymd('2021-12-31'), by = '1 day')))\n\nSave missing dates\n\nmissingdates <- anti_join(compdates, perday)\n\nAdd missing dates to our data set.\nfulldates <- rbind(perday, missingdates) #\nThis will give an error because we need the same arguments We need the same arguments\n\nmissingdates <- missingdates %>% \n  mutate(resc_counts = vector(mode = \"numeric\", length = length(.)))\n\nAdd now the missing dates to our data set\n\nfulldates <- rbind(perday, missingdates)\n\nAre any date duplicated?\n\ntable(duplicated(fulldates$date))\n\n\nFALSE \n 4748 \n\n\nWim Bernasco’s suggestion instead of using anti_join() and rbind(), use left_join.\n\nfulldates <- left_join(compdates, perday, by = \"date\") %>% \n  replace(is.na(.), 0)\n\nSeparate the date ymd\n\nfulldates <- fulldates %>% \n  mutate(year = year(date),\n         month = month(date),\n         day = day(date))\n\nWhat week of the year did it happen?\n\nfulldates <- fulldates %>% \n  mutate(week = week(date))\n\nWhat day of the week did it happen?\n\nfulldates <- fulldates %>% \n  mutate(weekday = wday(date, label = TRUE))"
  },
  {
    "objectID": "posts/04_TT/04_TT_202203.html",
    "href": "posts/04_TT/04_TT_202203.html",
    "title": "Sankey diagrams and how to create",
    "section": "",
    "text": "In this meeting, Tim Verlaan explains what Sankey diagrams are, and how they can be created in R [@verlaan_nsc-rn_2022]"
  },
  {
    "objectID": "posts/04_TT/04_TT_202203.html#get-started",
    "href": "posts/04_TT/04_TT_202203.html#get-started",
    "title": "Sankey diagrams and how to create",
    "section": "Get started",
    "text": "Get started\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(readr)\n\n\nrelig_income\n\n# A tibble: 18 x 11\n   religion      `<$10k` $10-2~1 $20-3~2 $30-4~3 $40-5~4 $50-7~5 $75-1~6 $100-~7\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Agnostic           27      34      60      81      76     137     122     109\n 2 Atheist            12      27      37      52      35      70      73      59\n 3 Buddhist           27      21      30      34      33      58      62      39\n 4 Catholic          418     617     732     670     638    1116     949     792\n 5 Don’t know/r~      15      14      15      11      10      35      21      17\n 6 Evangelical ~     575     869    1064     982     881    1486     949     723\n 7 Hindu               1       9       7       9      11      34      47      48\n 8 Historically~     228     244     236     238     197     223     131      81\n 9 Jehovah's Wi~      20      27      24      24      21      30      15      11\n10 Jewish             19      19      25      25      30      95      69      87\n11 Mainline Prot     289     495     619     655     651    1107     939     753\n12 Mormon             29      40      48      51      56     112      85      49\n13 Muslim              6       7       9      10       9      23      16       8\n14 Orthodox           13      17      23      32      32      47      38      42\n15 Other Christ~       9       7      11      13      13      14      18      14\n16 Other Faiths       20      33      40      46      49      63      46      40\n17 Other World ~       5       2       3       4       2       7       3       4\n18 Unaffiliated      217     299     374     365     341     528     407     321\n# ... with 2 more variables: `>150k` <dbl>, `Don't know/refused` <dbl>, and\n#   abbreviated variable names 1: `$10-20k`, 2: `$20-30k`, 3: `$30-40k`,\n#   4: `$40-50k`, 5: `$50-75k`, 6: `$75-100k`, 7: `$100-150k`\n\n\n\n?pivot_longer\n\n\npivot_longer(relig_income, !religion)\n\n# A tibble: 180 x 3\n   religion name               value\n   <chr>    <chr>              <dbl>\n 1 Agnostic <$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic >150k                 84\n10 Agnostic Don't know/refused    96\n# ... with 170 more rows\n\n\n\ndf <- relig_income |>\n  pivot_longer(!religion, names_to = 'income', values_to = 'count')\n\n\nbillboard\n\n# A tibble: 317 x 79\n   artist track date.ent~1   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9\n   <chr>  <chr> <date>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 2 Pac  Baby~ 2000-02-26    87    82    72    77    87    94    99    NA    NA\n 2 2Ge+h~ The ~ 2000-09-02    91    87    92    NA    NA    NA    NA    NA    NA\n 3 3 Doo~ Kryp~ 2000-04-08    81    70    68    67    66    57    54    53    51\n 4 3 Doo~ Loser 2000-10-21    76    76    72    69    67    65    55    59    62\n 5 504 B~ Wobb~ 2000-04-15    57    34    25    17    17    31    36    49    53\n 6 98^0   Give~ 2000-08-19    51    39    34    26    26    19     2     2     3\n 7 A*Tee~ Danc~ 2000-07-08    97    97    96    95   100    NA    NA    NA    NA\n 8 Aaliy~ I Do~ 2000-01-29    84    62    51    41    38    35    35    38    38\n 9 Aaliy~ Try ~ 2000-03-18    59    53    38    28    21    18    16    14    12\n10 Adams~ Open~ 2000-08-26    76    76    74    69    68    67    61    58    57\n# ... with 307 more rows, 67 more variables: wk10 <dbl>, wk11 <dbl>,\n#   wk12 <dbl>, wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>, wk17 <dbl>,\n#   wk18 <dbl>, wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>,\n#   wk24 <dbl>, wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>,\n#   wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>, wk35 <dbl>,\n#   wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>, wk41 <dbl>,\n#   wk42 <dbl>, wk43 <dbl>, wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, ...\n\n\n\nbillboard |>\n  pivot_longer(\n    cols = starts_with('wk'),\n    values_drop_na = TRUE,\n    names_to = \"week\",\n    values_to = 'rank',\n    names_prefix = \"wk\",\n    names_transform = list(week = as.integer)\n  )\n\n# A tibble: 5,307 x 5\n   artist  track                   date.entered  week  rank\n   <chr>   <chr>                   <date>       <int> <dbl>\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n# ... with 5,297 more rows\n\n\n\n#install.packages(\"remotes\")\n#remotes::install_github(\"davidsjoberg/ggsankey\")\nlibrary(ggsankey)\nlibrary(ggplot2)\n\n\n?mtcars\n\ndf <- mtcars |>\n  make_long(cyl, vs, am, gear, carb)\n\n\nggplot(df, aes(x = x,\n               node = node,\n               next_x = next_x,\n               next_node = next_node,\n               fill = factor(node),\n               label = node)) +\n  geom_sankey() +\n  geom_sankey_label() \n\n\n\n\nSankey graph\n\n\n\n\n\ndf1 <- mtcars |>\n  select(cyl, vs, am, gear, carb) |>\n  pivot_longer(everything()) |>\n  mutate(next_x = lead(.data$name),\n         next_node = lead(.data$value)\n  )"
  },
  {
    "objectID": "posts/welcome - kopie/index.html",
    "href": "posts/welcome - kopie/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/welcome - kopie (2)/index.html",
    "href": "posts/welcome - kopie (2)/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/welcome - kopie (3)/index.html",
    "href": "posts/welcome - kopie (3)/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/welcome - kopie (4)/index.html",
    "href": "posts/welcome - kopie (4)/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]